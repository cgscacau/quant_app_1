# quant_app_single.py â€” single-file runner
import os, json, runpy
FILES = {"requirements.txt": "streamlit>=1.37\nyfinance>=0.2.43\npandas>=2.2\nnumpy>=1.26\nplotly>=5.22\nscikit-learn>=1.5\nstatsmodels>=0.14\narch>=6.3\nscipy>=1.12", "README.md": "# Quant App â€” Ensemble de MÃ©todos com GestÃ£o de Risco\nVer README anterior.", "app.py": "import json\nfrom datetime import date, timedelta\nimport pandas as pd\nimport numpy as np\nimport streamlit as st\n\nfrom core.data import download_prices, add_features\nfrom core.utils import train_test_split_by_date, last_valid\nfrom core.models_arima import ARIMAModel\nfrom core.models_garch import GARCHModel\nfrom core.models_rf import RandomForestSignal\nfrom core.models_trend import TrendScoreModel\nfrom core.ensemble import weighted_ensemble\nfrom core.risk import entry_stop_gain, position_size, kelly_fraction\nfrom core.backtest import simulate_prob_strategy\nfrom core.visual import price_candles, line_series, equity_curve\n\nst.set_page_config(page_title=\"Quant App â€” Ensemble & Risco\", layout=\"wide\")\n\nst.sidebar.header(\"ConfiguraÃ§Ã£o\")\nwith open(\"assets/tickers.json\", \"r\", encoding=\"utf-8\") as f:\n    tickers = json.load(f)\n\nuniverso = st.sidebar.selectbox(\"Universo\", list(tickers.keys()), index=0)\nticker = st.sidebar.selectbox(\"Ativo\", tickers[universo], index=0)\n\ntoday = date.today()\nd_start = st.sidebar.date_input(\"Data inicial\", value=today - timedelta(days=365*5))\nd_end   = st.sidebar.date_input(\"Data final\", value=today)\ninterval = st.sidebar.selectbox(\"Intervalo\", [\"1d\",\"1h\",\"1wk\"], index=0)\n\nst.sidebar.subheader(\"Split Treino/Teste\")\ntrain_end_ratio = st.sidebar.slider(\"ProporÃ§Ã£o de Treino\", 0.5, 0.9, 0.7, 0.05)\n\nst.sidebar.subheader(\"Modelos e Pesos para Ensemble\")\nuse_arima  = st.sidebar.checkbox(\"ARIMA\", True)\nuse_garch  = st.sidebar.checkbox(\"GARCH (vol)\", True)\nuse_rf     = st.sidebar.checkbox(\"RandomForest (ML)\", True)\nuse_trend  = st.sidebar.checkbox(\"Trend Score (Logit)\", True)\n\nw_arima = st.sidebar.slider(\"Peso ARIMA\", 0.0, 1.0, 0.30, 0.05)\nw_garch = st.sidebar.slider(\"Peso GARCH\", 0.0, 1.0, 0.10, 0.05)\nw_rf    = st.sidebar.slider(\"Peso RF\",    0.0, 1.0, 0.40, 0.05)\nw_trend = st.sidebar.slider(\"Peso Trend\", 0.0, 1.0, 0.20, 0.05)\n\nst.sidebar.subheader(\"Risco & Trade\")\ncapital = st.sidebar.number_input(\"Capital (BRL/USD)\", 100000.0, step=1000.0)\nrisk_perc = st.sidebar.slider(\"Risco por trade (%)\", 0.0025, 0.05, 0.01, 0.0025)\natr_mult_stop = st.sidebar.slider(\"Stop (x ATR)\", 1.0, 5.0, 2.0, 0.5)\nrr = st.sidebar.slider(\"Risco:Retorno (R)\", 1.0, 5.0, 2.0, 0.5)\nth_buy = st.sidebar.slider(\"Threshold BUY\", 0.5, 0.9, 0.55, 0.01)\nth_sell = st.sidebar.slider(\"Threshold SELL\", 0.1, 0.5, 0.45, 0.01)\n\nst.title(\"ðŸ“ˆ Quant App â€” Ensemble de MÃ©todos com GestÃ£o de Risco\")\n\nwith st.spinner(\"Baixando dados do Yahoo Finance...\"):\n    px = download_prices(ticker, str(d_start), str(d_end), interval=interval)\n    if len(px) < 250:\n        st.warning(\"Poucos dados retornados â€” considere ampliar a janela ou usar outro intervalo.\")\n    df = add_features(px)\n\nsplit_idx = int(len(df) * train_end_ratio)\ntrain, test = df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n\nst.markdown(\"### PreÃ§o\")\nst.plotly_chart(price_candles(df), use_container_width=True)\n\nresults = []\nexplanations = []\n\nif use_arima:\n    arima = ARIMAModel(order=(1,0,0)).fit(train)\n    res_a = arima.predict_next(df)\n    results.append(res_a)\n    explanations.append((\"ARIMA\", res_a))\n\nif use_garch:\n    garch = GARCHModel().fit(train)\n    res_g = garch.predict_next(df)\n    results.append(res_g)\n    explanations.append((\"GARCH\", res_g))\n\nif use_rf:\n    rf = RandomForestSignal().fit(train, test)\n    res_rf = rf.predict_next(df)\n    results.append(res_rf)\n    explanations.append((\"RandomForest\", res_rf))\n\nif use_trend:\n    trend = TrendScoreModel().fit(train, test)\n    res_t = trend.predict_next(df)\n    results.append(res_t)\n    explanations.append((\"Trend\", res_t))\n\nweights = {'ARIMA': w_arima, 'GARCH': w_garch, 'RandomForest': w_rf, 'TrendScore': w_trend}\nens = weighted_ensemble(results, weights)\np_up = ens['prob_up']\ndirection = \"BUY\" if p_up >= th_buy else (\"SELL\" if p_up <= th_sell else \"NEUTRAL\")\n\nlast_close = float(df['Close'].iloc[-1])\nlast_atr = float(df['ATR14'].iloc[-1])\n\nfrom core.risk import entry_stop_gain, position_size, kelly_fraction\nentry = stop = gain = None\nqty = 0\nkelly_f = 0.0\n\nif direction != \"NEUTRAL\":\n    entry, stop, gain = entry_stop_gain(last_close, last_atr, direction, atr_mult_stop, rr)\n    qty = position_size(capital, entry, stop, risk_perc)\n    kelly_f = kelly_fraction(p_up if direction=='BUY' else (1-p_up), rr)\n\nc1, c2, c3, c4 = st.columns(4)\nc1.metric(\"Prob. de Alta (Ensemble)\", f\"{p_up:.1%}\")\nc2.metric(\"DireÃ§Ã£o\", direction)\nc3.metric(\"Ãšltimo Close\", f\"{last_close:,.2f}\")\nc4.metric(\"ATR(14)\", f\"{last_atr:,.2f}\")\n\nif direction != \"NEUTRAL\":\n    c5, c6, c7, c8 = st.columns(4)\n    c5.metric(\"Entrada\", f\"{entry:,.2f}\")\n    c6.metric(\"Stop\", f\"{stop:,.2f}\")\n    c7.metric(\"Alvo (R)\", f\"{gain:,.2f}\")\n    c8.metric(\"Qtd. sugerida\", f\"{qty:,}\")\n    st.caption(f\"Kelly fracionado sugerido: **{kelly_f:.2%}** (use fraÃ§Ã£o conservadora, ex. 0.5x).\")\n\nst.markdown(\"### ExplicaÃ§Ã£o dos Modelos\")\nfor name, res in explanations:\n    with st.expander(f\"{name} â€” detalhes\"):\n        st.write(res)\n\nst.markdown(\"### Backtest â€” PerÃ­odo de Teste\")\nprob_series = pd.Series(index=test.index, dtype=float).fillna(0.5)\neq, stats = simulate_prob_strategy(test, prob_series, threshold_buy=th_buy, threshold_sell=th_sell,\n                                   capital0=capital, risk_perc=risk_perc, atr_mult_stop=atr_mult_stop, rr=rr)\n\nc9, c10 = st.columns(2)\nwith c9:\n    st.plotly_chart(line_series(eq, 'Equity', title='Equity Curve'), use_container_width=True)\nwith c10:\n    st.dataframe(eq.tail(10))\n\nst.markdown(\"#### Indicadores do Backtest\")\nst.write(stats)\n\nst.caption(\"ProtÃ³tipo modular; para produÃ§Ã£o, implementar walk-forward, custos e tuning robusto.\")", "core/__init__.py": "", "core/utils.py": "from __future__ import annotations\nimport numpy as np\nimport pandas as pd\n\ndef safe_pct_change(s: pd.Series, periods:int=1) -> pd.Series:\n    try:\n        return s.pct_change(periods=periods).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n    except Exception:\n        return pd.Series([0.0]*len(s), index=s.index)\n\ndef zscore(x: pd.Series, window:int=20) -> pd.Series:\n    r = x.rolling(window)\n    return (x - r.mean()) / (r.std().replace(0, np.nan))\n\ndef last_valid(series: pd.Series, default=None):\n    try:\n        return series.dropna().iloc[-1]\n    except Exception:\n        return default\n\ndef train_test_split_by_date(df: pd.DataFrame, train_start, train_end, test_start, test_end):\n    train = df.loc[str(train_start):str(train_end)].copy()\n    test  = df.loc[str(test_start):str(test_end)].copy()\n    return train, test", "core/indicators.py": "import numpy as np\nimport pandas as pd\n\ndef ema(series: pd.Series, span:int=20) -> pd.Series:\n    return series.ewm(span=span, adjust=False).mean()\n\ndef rsi(close: pd.Series, period:int=14) -> pd.Series:\n    delta = close.diff()\n    up, down = delta.clip(lower=0), -delta.clip(upper=0)\n    roll_up = up.ewm(alpha=1/period, adjust=False).mean()\n    roll_down = down.ewm(alpha=1/period, adjust=False).mean()\n    rs = roll_up / (roll_down + 1e-12)\n    return 100 - (100 / (1 + rs))\n\ndef true_range(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n    prev_close = close.shift(1)\n    ranges = pd.concat([high - low, (high - prev_close).abs(), (low - prev_close).abs()], axis=1)\n    return ranges.max(axis=1)\n\ndef atr(high: pd.Series, low: pd.Series, close: pd.Series, period:int=14) -> pd.Series:\n    tr = true_range(high, low, close)\n    return tr.ewm(alpha=1/period, adjust=False).mean()\n\ndef macd(close: pd.Series, fast:int=12, slow:int=26, signal:int=9):\n    ema_fast = ema(close, fast)\n    ema_slow = ema(close, slow)\n    macd_line = ema_fast - ema_slow\n    signal_line = ema(macd_line, signal)\n    hist = macd_line - signal_line\n    return macd_line, signal_line, hist", "core/data.py": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom .indicators import rsi, atr, ema, macd\nfrom .utils import safe_pct_change\n\ndef download_prices(ticker:str, start:str, end:str, interval:str='1d') -> pd.DataFrame:\n    df = yf.download(ticker, start=start, end=end, interval=interval, auto_adjust=True, progress=False)\n    if isinstance(df.columns, pd.MultiIndex):\n        df.columns = [c[0].title() for c in df.columns]\n    df = df.rename(columns={c: c.title() for c in df.columns})\n    df = df.dropna().copy()\n    return df\n\ndef add_features(df: pd.DataFrame) -> pd.DataFrame:\n    out = df.copy()\n    out['Return'] = safe_pct_change(out['Close']).fillna(0.0)\n    out['LogRet'] = np.log1p(out['Return'])\n    out['RSI14'] = rsi(out['Close'], 14)\n    out['ATR14'] = atr(out['High'], out['Low'], out['Close'], 14)\n    out['EMA20'] = ema(out['Close'], 20)\n    out['EMA50'] = ema(out['Close'], 50)\n    out['EMA200'] = ema(out['Close'], 200)\n    macd_line, signal_line, hist = macd(out['Close'])\n    out['MACD'] = macd_line\n    out['MACDsig'] = signal_line\n    out['MACDhist'] = hist\n    out['Mom20'] = out['Close'] / out['Close'].shift(20) - 1\n    out['Vol20'] = out['Return'].rolling(20).std()\n    out = out.dropna().copy()\n    return out", "core/models_arima.py": "from __future__ import annotations\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom scipy.stats import norm\n\nclass ARIMAModel:\n    def __init__(self, order=(1,0,0)):\n        self.order = order\n        self.model_ = None\n        self.res_ = None\n\n    def fit(self, train: pd.DataFrame):\n        y = train['LogRet']\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            self.model_ = ARIMA(y, order=self.order, enforce_stationarity=False, enforce_invertibility=False)\n            self.res_ = self.model_.fit()\n        return self\n\n    def predict_next(self, recent: pd.DataFrame):\n        f = self.res_.get_forecast(steps=1)\n        mu = float(f.predicted_mean.iloc[-1])\n        sigma = float(f.se_mean.iloc[-1])\n        from math import isfinite\n        if not isfinite(sigma) or sigma<=0: sigma=1e-6\n        from scipy.stats import norm\n        p_up = 1.0 - norm.cdf(0.0, loc=mu, scale=sigma)\n        return {'model': 'ARIMA','order': self.order,'mu': mu,'sigma': sigma,'prob_up': p_up,\n                'explain': 'ARIMA(returns) â†’ P(r>0) via mÃ©dia e desvio previstos.'}", "core/models_garch.py": "from __future__ import annotations\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom arch import arch_model\n\nclass GARCHModel:\n    def __init__(self, p=1, q=1):\n        self.p, self.q = p, q\n        self.res_ = None\n\n    def fit(self, train: pd.DataFrame):\n        y = train['LogRet'] * 100.0\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            am = arch_model(y, mean='Constant', vol='GARCH', p=self.p, q=self.q, dist='normal')\n            self.res_ = am.fit(disp='off')\n        return self\n\n    def predict_next(self, recent: pd.DataFrame):\n        f = self.res_.forecast(horizon=1, reindex=False)\n        sigma_next = float(np.sqrt(f.variance.values[-1, -1]) / 100.0)\n        return {'model': 'GARCH','sigma_next': sigma_next,'prob_up': 0.5, 'explain': 'GARCH â†’ vol futura (direÃ§Ã£o neutra).'}", "core/models_rf.py": "from __future__ import annotations\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\n\nclass RandomForestSignal:\n    def __init__(self, n_estimators=300, max_depth=None, random_state=42):\n        self.model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state, n_jobs=-1)\n        self.scaler = None\n        self.feature_names_ = None\n        self.report_ = None\n\n    def _build_Xy(self, df: pd.DataFrame):\n        feats = ['RSI14','ATR14','EMA20','EMA50','EMA200','MACD','MACDsig','MACDhist','Mom20','Vol20']\n        X = df[feats].copy()\n        y = (df['Return'].shift(-1) > 0).astype(int)\n        X, y = X.iloc[:-1], y.iloc[:-1]\n        return X, y, feats\n\n    def fit(self, train: pd.DataFrame, test: pd.DataFrame):\n        Xtr, ytr, feats = self._build_Xy(train)\n        Xte, yte, _ = self._build_Xy(test)\n        self.feature_names_ = feats\n        self.scaler = StandardScaler()\n        Xtr_s = self.scaler.fit_transform(Xtr)\n        Xte_s = self.scaler.transform(Xte) if len(Xte)>0 else Xte\n        self.model.fit(Xtr_s, ytr)\n        if len(Xte)>0:\n            ypred = self.model.predict(Xte_s)\n            self.report_ = classification_report(yte, ypred, output_dict=True, zero_division=0)\n        return self\n\n    def predict_next(self, recent: pd.DataFrame):\n        X, _, _ = self._build_Xy(recent)\n        x_last = X.iloc[[-1]]\n        x_last_s = self.scaler.transform(x_last)\n        proba = float(self.model.predict_proba(x_last_s)[0,1])\n        return {'model': 'RandomForest','prob_up': proba,'feature_importances': dict(zip(self.feature_names_, self.model.feature_importances_)),\n                'report': self.report_,'explain': 'RandomForest em features tÃ©cnicas â†’ prob. de alta.'}", "core/models_trend.py": "from __future__ import annotations\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nclass TrendScoreModel:\n    def __init__(self):\n        self.clf = LogisticRegression(max_iter=200)\n        self.cols_ = None\n\n    def _features(self, df: pd.DataFrame) -> pd.DataFrame:\n        feats = pd.DataFrame(index=df.index)\n        feats['Close_over_EMA50'] = df['Close'] / (df['EMA50'] + 1e-12) - 1\n        feats['EMA20_over_EMA50'] = df['EMA20'] / (df['EMA50'] + 1e-12) - 1\n        feats['EMA50_over_EMA200'] = df['EMA50'] / (df['EMA200'] + 1e-12) - 1\n        feats['MACDhist'] = df['MACDhist']\n        feats['RSI14'] = df['RSI14']\n        feats['Mom20'] = df['Mom20']\n        feats = feats.fillna(0.0)\n        return feats\n\n    def fit(self, train: pd.DataFrame, test: pd.DataFrame):\n        Xtr = self._features(train).iloc[:-1]\n        ytr = (train['Return'].shift(-1) > 0).astype(int).iloc[:-1]\n        self.cols_ = Xtr.columns.tolist()\n        self.clf.fit(Xtr, ytr)\n        return self\n\n    def predict_next(self, recent: pd.DataFrame):\n        X = self._features(recent).iloc[[-2]]\n        proba = float(self.clf.predict_proba(X)[0,1])\n        return {'model': 'TrendScore','prob_up': proba,'explain': 'Momentum/EMAs/RSI via regressÃ£o logÃ­stica.'}", "core/ensemble.py": "from __future__ import annotations\nfrom typing import List, Dict\n\ndef weighted_ensemble(results: List[Dict], weights: Dict[str, float]) -> Dict:\n    present_models = {r['model'] for r in results}\n    w = {m: weights.get(m, 0.0) for m in present_models}\n    s = sum(w.values()) or 1.0\n    w = {m: v/s for m, v in w.items()}\n    p = sum(r['prob_up'] * w.get(r['model'], 0.0) for r in results)\n    return {'prob_up': p, 'weights': w}", "core/risk.py": "from __future__ import annotations\nimport numpy as np\nimport pandas as pd\n\ndef entry_stop_gain(last_close: float, atr_value: float, direction:str, atr_mult_stop:float=2.0, rr:float=2.0):\n    if direction == 'BUY':\n        entry = last_close\n        stop  = last_close - atr_mult_stop * atr_value\n        gain  = entry + rr * (entry - stop)\n    elif direction == 'SELL':\n        entry = last_close\n        stop  = last_close + atr_mult_stop * atr_value\n        gain  = entry - rr * (stop - entry)\n    else:\n        return None, None, None\n    return float(entry), float(stop), float(gain)\n\ndef position_size(capital: float, entry: float, stop: float, risk_perc: float=0.01):\n    risk_amount = capital * risk_perc\n    per_unit = abs(entry - stop)\n    if per_unit <= 1e-8:\n        return 0\n    qty = int(risk_amount // per_unit)\n    return max(qty, 0)\n\ndef kelly_fraction(prob_win: float, rr: float=2.0):\n    p = prob_win\n    b = rr\n    f = (p*(b+1)-1)/b\n    return max(0.0, min(f, 1.0))", "core/backtest.py": "from __future__ import annotations\nimport numpy as np\nimport pandas as pd\nfrom .risk import entry_stop_gain, position_size\n\ndef simulate_prob_strategy(df: pd.DataFrame, prob_series: pd.Series, threshold_buy=0.55, threshold_sell=0.45,\n                            capital0=100000.0, risk_perc=0.01, atr_mult_stop=2.0, rr=2.0):\n    eq = capital0\n    equity = []\n    pos_qty = 0\n    direction = None\n    entry = stop = take = None\n\n    for i in range(1, len(df)-1):\n        px = df['Close'].iloc[i]\n        atr = df['ATR14'].iloc[i]\n        p = prob_series.iloc[i]\n\n        if pos_qty != 0 and direction is not None:\n            if direction == 'BUY':\n                if df['Low'].iloc[i] <= stop:\n                    eq += pos_qty * (stop - entry)\n                    pos_qty = 0; direction = None\n                elif df['High'].iloc[i] >= take:\n                    eq += pos_qty * (take - entry)\n                    pos_qty = 0; direction = None\n            else:\n                if df['High'].iloc[i] >= stop:\n                    eq += pos_qty * (entry - stop)\n                    pos_qty = 0; direction = None\n                elif df['Low'].iloc[i] <= take:\n                    eq += pos_qty * (entry - take)\n                    pos_qty = 0; direction = None\n\n        if pos_qty == 0:\n            if p >= threshold_buy:\n                direction = 'BUY'\n                entry, stop, take = entry_stop_gain(px, atr, direction, atr_mult_stop, rr)\n                qty = position_size(eq, entry, stop, risk_perc)\n                pos_qty = qty\n            elif p <= threshold_sell:\n                direction = 'SELL'\n                entry, stop, take = entry_stop_gain(px, atr, direction, atr_mult_stop, rr)\n                qty = position_size(eq, entry, stop, risk_perc)\n                pos_qty = qty\n\n        equity.append(eq)\n\n    out = pd.DataFrame({'Equity': equity}, index=df.index[1:len(equity)+1])\n    out['Ret'] = out['Equity'].pct_change().fillna(0.0)\n    sharpe = np.sqrt(252) * out['Ret'].mean() / (out['Ret'].std() + 1e-12)\n    return out, {'final_equity': float(out['Equity'].iloc[-1]), 'sharpe': float(sharpe)}", "core/visual.py": "import plotly.graph_objects as go\nimport pandas as pd\n\ndef price_candles(df: pd.DataFrame):\n    fig = go.Figure(data=[go.Candlestick(\n        x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close']\n    )])\n    fig.update_layout(height=400, margin=dict(l=20,r=20,t=10,b=20))\n    return fig\n\ndef line_series(df: pd.DataFrame, y: str, title:str=''):\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=df.index, y=df[y], mode='lines', name=y))\n    fig.update_layout(title=title, height=300, margin=dict(l=20,r=20,t=30,b=20))\n    return fig\n\ndef equity_curve(df_eq: pd.DataFrame):\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=df_eq.index, y=df_eq['Equity'], mode='lines', name='Equity'))\n    fig.update_layout(title='Equity Curve', height=300, margin=dict(l=20,r=20,t=30,b=20))\n    return fig", "assets/tickers.json": "{\n  \"brasil\": [\n    \"PETR4.SA\",\n    \"VALE3.SA\",\n    \"BBAS3.SA\",\n    \"^BVSP\"\n  ],\n  \"usa\": [\n    \"AAPL\",\n    \"MSFT\",\n    \"GOOGL\",\n    \"AMZN\",\n    \"^GSPC\"\n  ],\n  \"crypto\": [\n    \"BTC-USD\",\n    \"ETH-USD\",\n    \"SOL-USD\"\n  ]\n}"}
def materialize_and_run():
    base = os.path.join(os.path.dirname(__file__), "_bundle")
    for rel, txt in FILES.items():
        full = os.path.join(base, rel)
        os.makedirs(os.path.dirname(full), exist_ok=True)
        with open(full, "w", encoding="utf-8") as f:
            f.write(txt)
    runpy.run_path(os.path.join(base, "app.py"), run_name="__main__")
if __name__ == "__main__":
    materialize_and_run()